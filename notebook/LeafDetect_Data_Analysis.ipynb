{
 "cells": [
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Data Analysis on CPU\n",
    "\n",
    "## Objective\n",
    "\n",
    "Understand ways to find a data set and to prepare a data set for machine learning and training.\n",
    "\n",
    "## Activities \n",
    "**In this section of the training you will**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing\n",
    "- Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "As you follow this notebook, complete **Activity** sections to finish this workload. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find a Data set\n"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Subset of the Data\n",
    "\n",
    "Although we used the initial data set during our initial exploration, we are only providing a subset of the relevant data used for training.  This means that you don't have download an 11GB dataset but instead just use the existing data set provided with the notebook.  We maintained the original folder structure of the dataset but removed classes we're not utilizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Infected Plant Disease: The Most Common Plant Disease found in the world.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.4 Select and Merge Interested Classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path\n",
    "import cv2\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Invalid, Corrupt and Non-JPG files\n",
    "\n",
    "\n",
    "In this section, we remove images that are not in \".jpg\" format or that can not be read by cv2 module. We're utilizing the multiprocessing function so that we can take advantage of all of the cores on our machine to make the process go quickly\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import vmmr_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n",
    "\n",
    "prcessed_leaf_path \n",
    "#Check Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(prcessed_leaf_path + \"/*/*\")\n",
    "    pool.map(vmmr_utils.check_image, image_list)\n",
    "    pool.close()\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distribution of Selected Classes\n",
    "\n",
    "\n",
    "Now, we can take a look at the class distribution of our problem statement. We're importing PyGal and creating a wrapper for rendering the chart inline, then passing in our data to the charting function.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pygal \n",
    "from IPython.display import display, HTML\n",
    "#Create function to display interactive plotting\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "    \n",
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Leaf Class Distribution'\n",
    "for o in os.listdir(prcessed_leaf_path):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(prcessed_leaf_path, o))))\n",
    "galplot(line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Confirm Folder Structure is Correct\n",
    "\n",
    "To summarize and confirm our progress, we can take a look at the folder tree structure in **Most_Infected_Leafs** to take a look at our images we used to create a smaller subset. \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm Folder Structure\n",
    "#Confirm Folder Structure\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease\"\n",
    "for root, dirs, files in os.walk(prcessed_leaf_path):\n",
    "    level = root.replace(os.getcwd(), '').count(os.sep)\n",
    "    print('{0}{1}/'.format('    ' * level, os.path.basename(root)))\n",
    "    for f in files[:2]:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), f))\n",
    "    if level is not 0:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), \"...\"))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Validation and Test Folders\n",
    "\n",
    "\n",
    "We need to create training, validation and test folders for data ingestion and we'll use 0.7, 0.1, 0.2 ratio for this purpose.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import vmmr_utils\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "#Train and Test Set Variables\n",
    "train_val_test_ratio = (.7,.1,.2) # 70/10/20 Data Split\n",
    "test_folder = '/hdd/data/leaf_data_set/plantdisease/test/'\n",
    "train_folder = '/hdd/data/leaf_data_set/plantdisease/train/'\n",
    "val_folder = '/hdd/data/leaf_data_set/plantdisease/val/'\n",
    "\n",
    "file_names = os.listdir('/hdd/data/leaf_data_set/plantdisease/processed')\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "for folder in [test_folder, train_folder, val_folder]:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder + category)\n",
    "    os.makedirs(train_folder + category)\n",
    "    os.makedirs(val_folder + category)\n",
    "\n",
    "#Split Data by Train Ratio and copy files to correct directory\n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(prcessed_leaf_path + '/' + category)\n",
    "    \n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Augmentation\n",
    "\n",
    "While looking at our distribution above we saw that certain classes were significantly lower than others.  To help mitigate that issue we're going to augment some of our data set so that we have a dataset that is more closely distributed.  Below we're taking a look at an example image and showing the effets of augmentation given a certain threshold of modification.  Then we're going to apply these random augmentations to our data.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Select a random image and follow the next step\n",
    "datagen = ImageDataGenerator(rotation_range=45, \n",
    "                             width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, \n",
    "                             zoom_range=0.3, \n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")\n",
    "#Load example image\n",
    "file_list = glob.glob(\"/hdd/data/leaf_data_set/plantdisease/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img = load_img(img_path)\n",
    "car_class = img_path.split(\"/\")[1]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original \" + car_class, fontsize=16)\n",
    "\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "#Apply different augmentation techniques\n",
    "n_augmentations = 4\n",
    "plt.figure(figsize=(15, 6))    \n",
    "i = 0\n",
    "for batch in datagen.flow(img, \n",
    "                          batch_size=1, \n",
    "                          seed=21):\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Augmented \" + car_class, fontsize=16)    \n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Augmented Dataset for Training \n",
    "\n",
    "\n",
    "By using the augmentation techniques we have learned, we can oversample minority classes in training set. We are not going to do these steps in validation or test in order not to create any bias on the data. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling Minority Classes in Training Set\n",
    "def data_augment(data_dir):\n",
    "    list_of_images = os.listdir(data_dir)\n",
    "    datagen = ImageDataGenerator(rotation_range=45, \n",
    "        horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    for img_name in list_of_images:\n",
    "        tmp_img_name = os.path.join(data_dir, img_name)\n",
    "        img = load_img(tmp_img_name)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        batch = datagen.flow(img, \n",
    "            batch_size=1, \n",
    "            seed=21,\n",
    "            save_to_dir=data_dir, \n",
    "            save_prefix=img_name.split(\".jpg\")[0] + \"augmented\", \n",
    "            save_format=\"jpg\")\n",
    "\n",
    "        batch.next()\n",
    "\n",
    "classes_to_augment = [\n",
    "        \"1.Apple_scab\",\n",
    "        \"10.Corn_Gray_leaf_spot\",\n",
    "        \"11.Corn_Northern_Leaf_Blight\",\n",
    "        \"12.Grape_Black_Measles\",\n",
    "        \"13.Grape_Black_rot\",\n",
    "        \"14.Grape_healthy\",\n",
    "        \"15.Grape_Leaf_blight\",\n",
    "        \"16.Orange_Citrus_greening\",\n",
    "        \"17.Peach_Bacterial_spot\",\n",
    "        \"18.Peach_healthy\",\n",
    "        \"19.Pepperbell_Bacterial_spot\",\n",
    "        \"2.Apple_Black_rot\",\n",
    "        \"20.Pepperbell_healthy\",\n",
    "        \"21.Potato_Early_blight\",\n",
    "        \"22.Potato_healthy\",\n",
    "        \"23.Potato_Late_blight\",\n",
    "        \"24.Raspberry_healthy\",\n",
    "        \"25.Soybean_healthy\",\n",
    "        \"26.Squash_Powdery_mildew\",\n",
    "        \"27.Strawberry_healthy\",\n",
    "        \"28.Strawberry_Leaf_scorch\",\n",
    "        \"29.Tomato_Bacterial_spot\",\n",
    "        \"3.Apple_Cedar_rust\",\n",
    "        \"30.Tomato_Early_blight\",\n",
    "        \"31.Tomato_healthy\",\n",
    "        \"32.Tomato_Late_blight\",\n",
    "        \"33.Tomato_Leaf_Mold\",\n",
    "        \"34.Tomato_mosaic_virus\",\n",
    "        \"35.Tomato_Septoria_leaf_spot\",\n",
    "        \"36.Tomato_Spider_mites\",\n",
    "        \"37.Tomato_Target_Spot\",\n",
    "        \"38.Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "        \"4.Apple_healthy\",\n",
    "        \"5.Blueberry_healthy\",\n",
    "        \"6.Cherry_healthy\",\n",
    "        \"7.Cherry_Powdery_mildew\",\n",
    "        \"8.Corn_Common_rust\",\n",
    "        \"9.Corn_healthy\"]\n",
    "\n",
    "\n",
    "for class_names in classes_to_augment:\n",
    "    print(\"Currently Augmenting:\", class_names)\n",
    "    data_dir = os.path.join(train_folder, class_names)\n",
    "    data_augment(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Images\n",
    "\n",
    "![Resize Images](assets/EDA_1-6.png)\n",
    "\n",
    "Depending on the toplogy, we need to resize the images with the expected image format. Since we're going to be using InceptionV3 in the next section we're going to match the size, 299x299, for that topology. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#Resize Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(train_folder + \"/*/*\")\n",
    "    func = partial(vmmr_utils.resize_image, size=299)\n",
    "    pool.map(func, image_list)\n",
    "    pool.close()\n",
    "\n",
    "vmmr_utils.display_images(train_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Distribution of Selected Classes again\n",
    "\n",
    "\n",
    "Now that we've done some augmentation to the dataset we want to see how the distribution has changed compared to before the augmentation.  In this case we're only going to be looking at the train folder, since we only augmented the train dataset, so the numbers will be slightly lower than the full dataset distribution graph from earlier.  \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Infected Leaf Training Class Distribution'\n",
    "for o in os.listdir(train_folder):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(train_folder, o))))\n",
    "galplot(line_chart)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "**In this section of the training you learned**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing and Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "You now should understand ways to find a data set and to prepare a data set for machine learning and training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
