{
 "cells": [
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Data Analysis on CPU\n",
    "\n",
    "## Objective\n",
    "\n",
    "Understand ways to find a data set and to prepare a data set for machine learning and training.\n",
    "\n",
    "## Activities \n",
    "**In this section of the training you will**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing\n",
    "- Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "As you follow this notebook, complete **Activity** sections to finish this workload. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Find a Data set\n"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Subset of the Data\n",
    "\n",
    "Although we used the initial data set during our initial exploration, we are only providing a subset of the relevant data used for training.  This means that you don't have download an 11GB dataset but instead just use the existing data set provided with the notebook.  We maintained the original folder structure of the dataset but removed classes we're not utilizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hottest Wheels: The Most Stolen New And Used Cars In The U.S.\n",
    "\n",
    "![Create Dataset for Problem](assets/EDA_1-1.png)\n",
    "\n",
    "The most popular vehicle in America—at least among thieves—is neither a rip-roaring sports car nor a plush luxury sedan. Heck, it’s not even an SUV. Instead, the most stolen vehicle is a plain vanilla 1996 Honda Civic that otherwise gets lost in a crowded parking lot. A total of 45,052 older-model Civics were pilfered last year. Among brand-new vehicles, another average family car tops the list, the Nissan Altima. Some 1,153 Altimas from the 2017 model year were taken last year.\n",
    "\n",
    "Here are the 10 most stolen used cars according to the NICB, with the most “popular” model year noted along with the total number of units from all model years taken:\n",
    "\n",
    "- Honda Civic (1998): 45,062\n",
    "- Honda Accord (1997): 43,764\n",
    "- Ford F-150 (2006): 35,105\n",
    "- Chevrolet Silverado (2004): 30.056\n",
    "- Toyota Camry (2017): 17,276\n",
    "- Nissan Altima (2016):  13,358\n",
    "- Toyota Corolla (2016): 12,337\n",
    "- Dodge/Ram Pickup (2001): 12,004\n",
    "- GMC Sierra (2017): 10,865\n",
    "- Chevrolet Impala (2008): 9,487\n",
    "\n",
    "### 1.4 Select and Merge Interested Classes\n",
    "\n",
    "In this section, we're going to look at merging cars that are the same Make/Model but look at the years nearby since cars usually look the same for 3-4 years before changing styles.  Below we'll see a dictionary containing the base car we're looking for and all the relevant cars that we're going to include in that category.\n",
    "\n",
    "Honda Civic (1998): 45,062\t        -> Honda Civic (1997 - 1998)\n",
    "Honda Accord (1997): 43,764\t        -> Honda Accord (1996 - 1997)\n",
    "Ford F-150 (2006): 35,105\t        -> Ford F150 (2005 - 2007)\n",
    "Chevrolet Silverado (2004): 30,056\t-> Chevrolet Silverado (2003 - 2004)\n",
    "Toyota Camry (2017): 17,276         -> Toyota Camry (2012 - 2014)\n",
    "Nissan Altima (2016):  13,358       -> Nissan Altima (2013 - 2015)\n",
    "Toyota Corolla (2016): 12,337       -> Toyota Corolla (2011 - 2013)\n",
    "Dodge/Ram Pickup (2001): 12,004\t    -> Dodge Ram 1500 (1995 - 2001)\n",
    "GMC Sierra (2017): 10,865           -> GMC Sierra 1500 (2007 - 2013)\n",
    "Chevrolet Impala (2008): 9,487\t    -> Chevrolet Impala (2007 - 2009)\n",
    "\n",
    "After merging the directories appropriately we're going take a look at a random subset of images in each of the categories.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path\n",
    "import cv2\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Invalid, Corrupt and Non-JPG files\n",
    "\n",
    "![Clean images](assets/EDA_1-2.png)\n",
    "\n",
    "In this section, we remove images that are not in \".jpg\" format or that can not be read by cv2 module. We're utilizing the multiprocessing function so that we can take advantage of all of the cores on our machine to make the process go quickly\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import vmmr_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n",
    "\n",
    "prcessed_leaf_path \n",
    "#Check Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(prcessed_leaf_path + \"/*/*\")\n",
    "    pool.map(vmmr_utils.check_image, image_list)\n",
    "    pool.close()\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distribution of Selected Classes\n",
    "\n",
    "![View Data Distribution](assets/EDA_1-3.png)\n",
    "\n",
    "Now, we can take a look at the class distribution of our problem statement. We're importing PyGal and creating a wrapper for rendering the chart inline, then passing in our data to the charting function.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pygal \n",
    "from IPython.display import display, HTML\n",
    "#Create function to display interactive plotting\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "    \n",
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Leaf Class Distribution'\n",
    "for o in os.listdir(prcessed_leaf_path):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(prcessed_leaf_path, o))))\n",
    "galplot(line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Confirm Folder Structure is Correct\n",
    "\n",
    "To summarize and confirm our progress, we can take a look at the folder tree structure in **Most_Stolen_Cars** to take a look at our images we used to create a smaller subset. \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm Folder Structure\n",
    "#Confirm Folder Structure\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease\"\n",
    "for root, dirs, files in os.walk(prcessed_leaf_path):\n",
    "    level = root.replace(os.getcwd(), '').count(os.sep)\n",
    "    print('{0}{1}/'.format('    ' * level, os.path.basename(root)))\n",
    "    for f in files[:2]:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), f))\n",
    "    if level is not 0:\n",
    "        print('{0}{1}'.format('    ' * (level + 1), \"...\"))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Validation and Test Folders\n",
    "\n",
    "![Create Data Folders](assets/EDA_1-4.png)\n",
    "\n",
    "We need to create training, validation and test folders for data ingestion and we'll use 0.7, 0.1, 0.2 ratio for this purpose.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import vmmr_utils\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "#Train and Test Set Variables\n",
    "train_val_test_ratio = (.7,.1,.2) # 70/10/20 Data Split\n",
    "test_folder = '/hdd/data/leaf_data_set/plantdisease/test/'\n",
    "train_folder = '/hdd/data/leaf_data_set/plantdisease/train/'\n",
    "val_folder = '/hdd/data/leaf_data_set/plantdisease/val/'\n",
    "\n",
    "file_names = os.listdir('/hdd/data/leaf_data_set/plantdisease/processed')\n",
    "\n",
    "prcessed_leaf_path = \"/hdd/data/leaf_data_set/plantdisease/processed\"\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "for folder in [test_folder, train_folder, val_folder]:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder + category)\n",
    "    os.makedirs(train_folder + category)\n",
    "    os.makedirs(val_folder + category)\n",
    "\n",
    "#Split Data by Train Ratio and copy files to correct directory\n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(prcessed_leaf_path + '/' + category)\n",
    "    \n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(prcessed_leaf_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Augmentation\n",
    "\n",
    "While looking at our distribution above we saw that certain classes were significantly lower than others.  To help mitigate that issue we're going to augment some of our data set so that we have a dataset that is more closely distributed.  Below we're taking a look at an example image and showing the effets of augmentation given a certain threshold of modification.  Then we're going to apply these random augmentations to our data.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Select a random image and follow the next step\n",
    "datagen = ImageDataGenerator(rotation_range=45, \n",
    "                             width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, \n",
    "                             zoom_range=0.3, \n",
    "                             vertical_flip=True,\n",
    "                             horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")\n",
    "#Load example image\n",
    "file_list = glob.glob(\"/hdd/data/leaf_data_set/plantdisease/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img = load_img(img_path)\n",
    "car_class = img_path.split(\"/\")[1]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original \" + car_class, fontsize=16)\n",
    "\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "#Apply different augmentation techniques\n",
    "n_augmentations = 4\n",
    "plt.figure(figsize=(15, 6))    \n",
    "i = 0\n",
    "for batch in datagen.flow(img, \n",
    "                          batch_size=1, \n",
    "                          seed=21):\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle(\"Augmented \" + car_class, fontsize=16)    \n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Augmented Dataset for Training \n",
    "\n",
    "![Data Augmentation](assets/EDA_1-5.png)\n",
    "\n",
    "By using the augmentation techniques we have learned, we can oversample minority classes in training set. We are not going to do these steps in validation or test in order not to create any bias on the data. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling Minority Classes in Training Set\n",
    "def data_augment(data_dir):\n",
    "    list_of_images = os.listdir(data_dir)\n",
    "    datagen = ImageDataGenerator(rotation_range=45, \n",
    "        horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    for img_name in list_of_images:\n",
    "        tmp_img_name = os.path.join(data_dir, img_name)\n",
    "        img = load_img(tmp_img_name)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        batch = datagen.flow(img, \n",
    "            batch_size=1, \n",
    "            seed=21,\n",
    "            save_to_dir=data_dir, \n",
    "            save_prefix=img_name.split(\".jpg\")[0] + \"augmented\", \n",
    "            save_format=\"jpg\")\n",
    "\n",
    "        batch.next()\n",
    "\n",
    "classes_to_augment = [\n",
    "        \"1.Apple_scab\",\n",
    "        \"10.Corn_Gray_leaf_spot\",\n",
    "        \"11.Corn_Northern_Leaf_Blight\",\n",
    "        \"12.Grape_Black_Measles\",\n",
    "        \"13.Grape_Black_rot\",\n",
    "        \"14.Grape_healthy\",\n",
    "        \"15.Grape_Leaf_blight\",\n",
    "        \"16.Orange_Citrus_greening\",\n",
    "        \"17.Peach_Bacterial_spot\",\n",
    "        \"18.Peach_healthy\",\n",
    "        \"19.Pepperbell_Bacterial_spot\",\n",
    "        \"2.Apple_Black_rot\",\n",
    "        \"20.Pepperbell_healthy\",\n",
    "        \"21.Potato_Early_blight\",\n",
    "        \"22.Potato_healthy\",\n",
    "        \"23.Potato_Late_blight\",\n",
    "        \"24.Raspberry_healthy\",\n",
    "        \"25.Soybean_healthy\",\n",
    "        \"26.Squash_Powdery_mildew\",\n",
    "        \"27.Strawberry_healthy\",\n",
    "        \"28.Strawberry_Leaf_scorch\",\n",
    "        \"29.Tomato_Bacterial_spot\",\n",
    "        \"3.Apple_Cedar_rust\",\n",
    "        \"30.Tomato_Early_blight\",\n",
    "        \"31.Tomato_healthy\",\n",
    "        \"32.Tomato_Late_blight\",\n",
    "        \"33.Tomato_Leaf_Mold\",\n",
    "        \"34.Tomato_mosaic_virus\",\n",
    "        \"35.Tomato_Septoria_leaf_spot\",\n",
    "        \"36.Tomato_Spider_mites\",\n",
    "        \"37.Tomato_Target_Spot\",\n",
    "        \"38.Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "        \"4.Apple_healthy\",\n",
    "        \"5.Blueberry_healthy\",\n",
    "        \"6.Cherry_healthy\",\n",
    "        \"7.Cherry_Powdery_mildew\",\n",
    "        \"8.Corn_Common_rust\",\n",
    "        \"9.Corn_healthy\"]\n",
    "\n",
    "\n",
    "for class_names in classes_to_augment:\n",
    "    print(\"Currently Augmenting:\", class_names)\n",
    "    data_dir = os.path.join(train_folder, class_names)\n",
    "    data_augment(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Images\n",
    "\n",
    "![Resize Images](assets/EDA_1-6.png)\n",
    "\n",
    "Depending on the toplogy, we need to resize the images with the expected image format. Since we're going to be using InceptionV3 in the next section we're going to match the size, 299x299, for that topology. \n",
    "\n",
    "**Activity**\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#Resize Images\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    image_list = glob.glob(train_folder + \"/*/*\")\n",
    "    func = partial(vmmr_utils.resize_image, size=299)\n",
    "    pool.map(func, image_list)\n",
    "    pool.close()\n",
    "\n",
    "vmmr_utils.display_images(train_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Distribution of Selected Classes again\n",
    "\n",
    "![View New Data Distribution](assets/EDA_1-7.png)\n",
    "\n",
    "Now that we've done some augmentation to the dataset we want to see how the distribution has changed compared to before the augmentation.  In this case we're only going to be looking at the train folder, since we only augmented the train dataset, so the numbers will be slightly lower than the full dataset distribution graph from earlier.  \n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Infected Leaf Training Class Distribution'\n",
    "for o in os.listdir(train_folder):\n",
    "    line_chart.add(o, len(os.listdir(os.path.join(train_folder, o))))\n",
    "galplot(line_chart)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "**In this section of the training you learned**\n",
    "- Fetch and visually inspect a dataset \n",
    "- Create a dataset to address a real life problem\n",
    "- Image Preprocessing and Data Augmentation Techniques\n",
    "- Address Imbalanced Dataset Problem\n",
    "- Organize a dataset into training, validation and testing groups\n",
    "- Finalize an augmented dataset for training, and testing\n",
    "\n",
    "You now should understand ways to find a data set and to prepare a data set for machine learning and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "A Large and Diverse Dataset for Improved Vehicle Make and Model Recognition\n",
    "F. Tafazzoli, K. Nishiyama and H. Frigui\n",
    "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops 2017. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
