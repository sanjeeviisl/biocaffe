{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD7 Training for Leaf Detect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd7 import build_model\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
    "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set the model configuration parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "img_height = 256 # Height of the input images\n",
    "img_width = 256 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "n_classes = 31 # Number of positive classes\n",
    "scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxesimport requests \n",
    "two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
    "clip_boxes = True # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
    "normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build or load the model\n",
    "\n",
    "You will want to execute either of the two code cells in the subsequent two sub-sections, not both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create a new model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /hdd/biocaffe/notebook/ssd/keras_loss_function/keras_ssd_loss.py:133: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /hdd/biocaffe/notebook/ssd/keras_loss_function/keras_ssd_loss.py:74: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /hdd/biocaffe/notebook/ssd/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 256, 256, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 256, 256, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 32) 2432        input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 256, 256, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu1 (ELU)                      (None, 256, 256, 32) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 128, 128, 32) 0           elu1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 128, 128, 48) 13872       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 128, 128, 48) 192         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu2 (ELU)                      (None, 128, 128, 48) 0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 64, 64, 48)   0           elu2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 64, 64, 64)   27712       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64, 64, 64)   256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu3 (ELU)                      (None, 64, 64, 64)   0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 32, 32, 64)   0           elu3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 32, 32, 64)   36928       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 32, 32, 64)   256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu4 (ELU)                      (None, 32, 32, 64)   0           bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 16, 16, 64)   0           elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 16, 16, 48)   27696       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 16, 16, 48)   192         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu5 (ELU)                      (None, 16, 16, 48)   0           bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 8, 8, 48)     0           elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 8, 8, 48)     20784       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 8, 8, 48)     192         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu6 (ELU)                      (None, 8, 8, 48)     0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling2D)            (None, 4, 4, 48)     0           elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 4, 4, 32)     13856       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn7 (BatchNormalization)        (None, 4, 4, 32)     128         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu7 (ELU)                      (None, 4, 4, 32)     0           bn7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "classes4 (Conv2D)               (None, 32, 32, 128)  73856       elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes5 (Conv2D)               (None, 16, 16, 128)  55424       elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes6 (Conv2D)               (None, 8, 8, 128)    55424       elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes7 (Conv2D)               (None, 4, 4, 128)    36992       elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes4 (Conv2D)                 (None, 32, 32, 16)   9232        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes5 (Conv2D)                 (None, 16, 16, 16)   6928        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes6 (Conv2D)                 (None, 8, 8, 16)     6928        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes7 (Conv2D)                 (None, 4, 4, 16)     4624        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes4_reshape (Reshape)      (None, 4096, 32)     0           classes4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes5_reshape (Reshape)      (None, 1024, 32)     0           classes5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes6_reshape (Reshape)      (None, 256, 32)      0           classes6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes7_reshape (Reshape)      (None, 64, 32)       0           classes7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors4 (AnchorBoxes)          (None, 32, 32, 4, 8) 0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors5 (AnchorBoxes)          (None, 16, 16, 4, 8) 0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors6 (AnchorBoxes)          (None, 8, 8, 4, 8)   0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors7 (AnchorBoxes)          (None, 4, 4, 4, 8)   0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classes_concat (Concatenate)    (None, 5440, 32)     0           classes4_reshape[0][0]           \n",
      "                                                                 classes5_reshape[0][0]           \n",
      "                                                                 classes6_reshape[0][0]           \n",
      "                                                                 classes7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "boxes4_reshape (Reshape)        (None, 4096, 4)      0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes5_reshape (Reshape)        (None, 1024, 4)      0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes6_reshape (Reshape)        (None, 256, 4)       0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes7_reshape (Reshape)        (None, 64, 4)        0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4_reshape (Reshape)      (None, 4096, 8)      0           anchors4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors5_reshape (Reshape)      (None, 1024, 8)      0           anchors5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors6_reshape (Reshape)      (None, 256, 8)       0           anchors6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors7_reshape (Reshape)      (None, 64, 8)        0           anchors7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes_softmax (Activation)    (None, 5440, 32)     0           classes_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes_concat (Concatenate)      (None, 5440, 4)      0           boxes4_reshape[0][0]             \n",
      "                                                                 boxes5_reshape[0][0]             \n",
      "                                                                 boxes6_reshape[0][0]             \n",
      "                                                                 boxes7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "anchors_concat (Concatenate)    (None, 5440, 8)      0           anchors4_reshape[0][0]           \n",
      "                                                                 anchors5_reshape[0][0]           \n",
      "                                                                 anchors6_reshape[0][0]           \n",
      "                                                                 anchors7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 5440, 44)     0           classes_softmax[0][0]            \n",
      "                                                                 boxes_concat[0][0]               \n",
      "                                                                 anchors_concat[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 394,032\n",
      "Trainable params: 393,360\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = build_model(image_size=(img_height, img_width, img_channels),\n",
    "                    n_classes=n_classes,\n",
    "                    mode='training',\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=scales,\n",
    "                    aspect_ratios_global=aspect_ratios,\n",
    "                    aspect_ratios_per_layer=None,\n",
    "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                    steps=steps,\n",
    "                    offsets=offsets,\n",
    "                    clip_boxes=clip_boxes,\n",
    "                    variances=variances,\n",
    "                    normalize_coords=normalize_coords,\n",
    "                    subtract_mean=intensity_mean,\n",
    "                    divide_by_stddev=intensity_range)\n",
    "\n",
    "# 2: Optional: Load some weights\n",
    "\n",
    "#model.load_weights('./ssd7_weights.h5', by_name=True)\n",
    "\n",
    "\n",
    "weights_path = 'VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "\n",
    "#weights_path = 'ssd7_leaf10_epoch-117.h5'\n",
    "\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an Adam optimizer and the SSD loss function and compile the model\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load a saved model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 256, 256, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 256, 256, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 32) 2432        input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 256, 256, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu1 (ELU)                      (None, 256, 256, 32) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 128, 128, 32) 0           elu1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 128, 128, 48) 13872       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 128, 128, 48) 192         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu2 (ELU)                      (None, 128, 128, 48) 0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 64, 64, 48)   0           elu2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 64, 64, 64)   27712       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64, 64, 64)   256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu3 (ELU)                      (None, 64, 64, 64)   0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 32, 32, 64)   0           elu3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 32, 32, 64)   36928       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 32, 32, 64)   256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu4 (ELU)                      (None, 32, 32, 64)   0           bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 16, 16, 64)   0           elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 16, 16, 48)   27696       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 16, 16, 48)   192         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu5 (ELU)                      (None, 16, 16, 48)   0           bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 8, 8, 48)     0           elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 8, 8, 48)     20784       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 8, 8, 48)     192         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu6 (ELU)                      (None, 8, 8, 48)     0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling2D)            (None, 4, 4, 48)     0           elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 4, 4, 32)     13856       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn7 (BatchNormalization)        (None, 4, 4, 32)     128         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu7 (ELU)                      (None, 4, 4, 32)     0           bn7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "classes4 (Conv2D)               (None, 32, 32, 128)  73856       elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes5 (Conv2D)               (None, 16, 16, 128)  55424       elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes6 (Conv2D)               (None, 8, 8, 128)    55424       elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes7 (Conv2D)               (None, 4, 4, 128)    36992       elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes4 (Conv2D)                 (None, 32, 32, 16)   9232        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes5 (Conv2D)                 (None, 16, 16, 16)   6928        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes6 (Conv2D)                 (None, 8, 8, 16)     6928        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes7 (Conv2D)                 (None, 4, 4, 16)     4624        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes4_reshape (Reshape)      (None, 4096, 32)     0           classes4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes5_reshape (Reshape)      (None, 1024, 32)     0           classes5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes6_reshape (Reshape)      (None, 256, 32)      0           classes6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes7_reshape (Reshape)      (None, 64, 32)       0           classes7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors4 (AnchorBoxes)          (None, 32, 32, 4, 8) 0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors5 (AnchorBoxes)          (None, 16, 16, 4, 8) 0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors6 (AnchorBoxes)          (None, 8, 8, 4, 8)   0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors7 (AnchorBoxes)          (None, 4, 4, 4, 8)   0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classes_concat (Concatenate)    (None, 5440, 32)     0           classes4_reshape[0][0]           \n",
      "                                                                 classes5_reshape[0][0]           \n",
      "                                                                 classes6_reshape[0][0]           \n",
      "                                                                 classes7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "boxes4_reshape (Reshape)        (None, 4096, 4)      0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes5_reshape (Reshape)        (None, 1024, 4)      0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes6_reshape (Reshape)        (None, 256, 4)       0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes7_reshape (Reshape)        (None, 64, 4)        0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4_reshape (Reshape)      (None, 4096, 8)      0           anchors4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors5_reshape (Reshape)      (None, 1024, 8)      0           anchors5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors6_reshape (Reshape)      (None, 256, 8)       0           anchors6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors7_reshape (Reshape)      (None, 64, 8)        0           anchors7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes_softmax (Activation)    (None, 5440, 32)     0           classes_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes_concat (Concatenate)      (None, 5440, 4)      0           boxes4_reshape[0][0]             \n",
      "                                                                 boxes5_reshape[0][0]             \n",
      "                                                                 boxes6_reshape[0][0]             \n",
      "                                                                 boxes7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "anchors_concat (Concatenate)    (None, 5440, 8)      0           anchors4_reshape[0][0]           \n",
      "                                                                 anchors5_reshape[0][0]           \n",
      "                                                                 anchors6_reshape[0][0]           \n",
      "                                                                 anchors7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 5440, 44)     0           classes_softmax[0][0]            \n",
      "                                                                 boxes_concat[0][0]               \n",
      "                                                                 anchors_concat[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 394,032\n",
      "Trainable params: 393,360\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "#model_path = 'ssd7_leaf10_epoch-117.h5'\n",
    "\n",
    "model_path = 'ssd7_leaf31_epoch-02.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up the data generators for the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image set 'trainval.txt': 100%|██████████| 2024/2024 [00:39<00:00, 51.09it/s]\n",
      "Processing image set 'test.txt': 100%|██████████| 71/71 [00:00<00:00, 246.67it/s]\n",
      "Creating HDF5 dataset: 100%|██████████| 2024/2024 [00:34<00:00, 58.44it/s] \n",
      "Creating HDF5 dataset: 100%|██████████| 71/71 [00:00<00:00, 275.64it/s]\n",
      "Number of images in the training dataset:\t  2024\n",
      "Number of images in the validation dataset:\t    71\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "VOC_2019_images_dir      = '/hdd/data/LeafDetectData/LEAF2019/JPEGImages/'\n",
    "\n",
    "# The directories that contain the annotations.\n",
    "VOC_2019_annotations_dir      = '/hdd/data/LeafDetectData/LEAF2019/Annotations/'\n",
    "\n",
    "# The paths to the image sets.\n",
    "VOC_2019_trainval_image_set_filename = '/hdd/data/LeafDetectData/LEAF2019/ImageSets/Main/trainval.txt'\n",
    "VOC_2019_test_image_set_filename     = '/hdd/data/LeafDetectData/LEAF2019/ImageSets/Main/test.txt'\n",
    "\n",
    "#classes = ['background','Potato_healthy','Potato_Early_blight','Infected_Potato_Early_blight',\n",
    "#           'Potato_Late_blight','Infected_Potato_Late_blight','Tomato_healthy',\n",
    "#           'Tomato_Early_blight','Infected_Tomato_Early_blight','Tomato_Late_blight','Infected_Tomato_Late_blight']\n",
    "\n",
    "classes = [ 'background',\n",
    "            'Potato_healthy',\n",
    "            'Infected_Potato_Early_blight',\n",
    "            'Potato_Early_blight',\n",
    "            'Infected_Potato_Late_blight',\n",
    "            'Potato_Late_blight',\n",
    "            'Tomato_healthy',\n",
    "            'Infected_Tomato_Septoria_spot',\n",
    "            'Tomato_Septoria_spot',\n",
    "            'Infected_Tomato_Spider_mites',\n",
    "            'Tomato_Spider_mites',\n",
    "            'Infected_Tomato_Target_Spot',\n",
    "            'Tomato_Target_Spot',\n",
    "            'Infected_Tomato_Curl_Virus',\n",
    "            'Tomato_Curl_Virus',\n",
    "            'Infected_Tomato_mosaic_virus',\n",
    "            'Tomato_mosaic_virus',\n",
    "            'Infected_Tomato_Leaf_Mold',\n",
    "            'Tomato_Leaf_Mold',\n",
    "            'Infected_Tomato_Bacterial_spot',\n",
    "            'Tomato_Bacterial_spot',\n",
    "            'Infected_Tomato_Early_blight',\n",
    "            'Tomato_Early_blight',\n",
    "            'Infected_Tomato_Late_blight',\n",
    "            'Tomato_Late_blight',\n",
    "            'Corn_healthy',\n",
    "            'Infected_Corn_Common_rust',\n",
    "            'Corn_Common_rust',\n",
    "            'Infected_Corn_Gray_leaf',\n",
    "            'Corn_Gray_leaf',\n",
    "            'Infected_Corn_Northern_Blight',\n",
    "            'Corn_Northern_Blight'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "train_dataset.parse_xml(images_dirs=[VOC_2019_images_dir],\n",
    "                        image_set_filenames=[VOC_2019_trainval_image_set_filename],\n",
    "                        annotations_dirs=[VOC_2019_annotations_dir],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "val_dataset.parse_xml(images_dirs=[VOC_2019_images_dir],\n",
    "                      image_set_filenames=[VOC_2019_test_image_set_filename],\n",
    "                      annotations_dirs=[VOC_2019_annotations_dir],\n",
    "                      classes=classes,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=True,\n",
    "                      ret=False)\n",
    "\n",
    "\n",
    "train_dataset.create_hdf5_dataset(file_path='dataset_ssd7_31leaf_2019_trainval.h5',\n",
    "                                  resize=False,\n",
    "                                  variable_image_size=True,\n",
    "                                  verbose=True)\n",
    "\n",
    "val_dataset.create_hdf5_dataset(file_path='dataset_ssd7_31leaf_2019_test.h5',\n",
    "                                resize=False,\n",
    "                                variable_image_size=True,\n",
    "                                verbose=True)\n",
    "\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# 4: Define the image processing chain.\n",
    "\n",
    "data_augmentation_chain = DataAugmentationConstantInputSize(random_brightness=(-48, 48, 0.5),\n",
    "                                                            random_contrast=(0.5, 1.8, 0.5),\n",
    "                                                            random_saturation=(0.5, 1.8, 0.5),\n",
    "                                                            random_hue=(18, 0.5),\n",
    "                                                            random_flip=0.5,\n",
    "                                                            random_translate=((0.03,0.5), (0.03,0.5), 0.5),\n",
    "                                                            random_scale=(0.5, 2.0, 0.5),\n",
    "                                                            n_trials_max=3,\n",
    "                                                            clip_boxes=True,\n",
    "                                                            overlap_criterion='area',\n",
    "                                                            bounds_box_filter=(0.3, 1.0),\n",
    "                                                            bounds_validator=(0.5, 1.0),\n",
    "                                                            n_boxes_min=1,\n",
    "                                                            background=(0,0,0))\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n",
    "                   model.get_layer('classes5').output_shape[1:3],\n",
    "                   model.get_layer('classes6').output_shape[1:3],\n",
    "                   model.get_layer('classes7').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_global=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.3,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[data_augmentation_chain],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set the remaining training parameters and train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the weights.\n",
    "model_checkpoint = ModelCheckpoint(filepath='ssd7_leaf31_epoch-{epoch:02d}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='ssd7_leaf31_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.2,\n",
    "                                         patience=8,\n",
    "                                         verbose=1,\n",
    "                                         epsilon=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.00001)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "             reduce_learning_rate]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      " 385/1000 [==========>...................] - ETA: 35:33 - loss: 3.6504"
     ]
    }
   ],
   "source": [
    "# TODO: Set the epochs to train for.\n",
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 2\n",
    "final_epoch     = 200\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the training and validation loss evolved to check whether our training is going in the right direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(loc='upper right', prop={'size': 24});\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loss has been decreasing at a similar pace as the training loss, indicating that our model has been learning effectively over the last 30 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Set the generator for the predictions.\n",
    "\n",
    "predict_generator = val_dataset.generate(batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'processed_labels',\n",
    "                                                  'filenames'},\n",
    "                                         keep_images_without_gt=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Generate samples\n",
    "\n",
    "batch_images, batch_labels, batch_filenames = next(predict_generator)\n",
    "\n",
    "i = 0 # Which batch item to look at\n",
    "\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "print()\n",
    "print(\"Ground truth boxes:\\n\")\n",
    "print(batch_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Make a prediction\n",
    "\n",
    "y_pred = model.predict(batch_images)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's decode the raw predictions in `y_pred`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Decode the raw prediction `y_pred`\n",
    "\n",
    "y_pred_decoded = decode_detections(y_pred,\n",
    "                                   confidence_thresh=0.8,\n",
    "                                   iou_threshold=0.45,\n",
    "                                   top_k=200,\n",
    "                                   normalize_coords=normalize_coords,\n",
    "                                   img_height=img_height,\n",
    "                                   img_width=img_width)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_decoded[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's draw the predicted boxes onto the image. Each predicted box says its confidence next to the category name. The ground truth boxes are also drawn onto the image in green for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: Draw the predicted boxes onto the image\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imshow(batch_images[i])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist() # Set the colors for the bounding boxes\n",
    "#classes = ['background','Potato_healthy','Potato_Early_blight','Infected_Potato_Early_blight_Leaf',\n",
    "#           'Potato_Late_blight_Spot','Infected_Potato_Late_blight_Leaf','Tomato_healthy',\n",
    "#           'Tomato_Early_blight_Spot','Infected_Tomato_Early_blight_Leaf','Tomato_Late_blight_Spot','Infected_Tomato_Late_blight_Leaf']\n",
    "\n",
    "classes = [ 'background',\n",
    "            'Potato_healthy',\n",
    "            'Infected_Potato_Early_blight',\n",
    "            'Potato_Early_blight',\n",
    "            'Infected_Potato_Late_blight',\n",
    "            'Potato_Late_blight',\n",
    "            'Tomato_healthy',\n",
    "            'Infected_Tomato_Septoria_spot',\n",
    "            'Tomato_Septoria_spot',\n",
    "            'Infected_Tomato_Spider_mites',\n",
    "            'Tomato_Spider_mites',\n",
    "            'Infected_Tomato_Target_Spot',\n",
    "            'Tomato_Target_Spot',\n",
    "            'Infected_Tomato_Curl_Virus',\n",
    "            'Tomato_Curl_Virus',\n",
    "            'Infected_Tomato_mosaic_virus',\n",
    "            'Tomato_mosaic_virus',\n",
    "            'Infected_Tomato_Leaf_Mold',\n",
    "            'Tomato_Leaf_Mold',\n",
    "            'Infected_Tomato_Bacterial_spot',\n",
    "            'Tomato_Bacterial_spot',\n",
    "            'Infected_Tomato_Early_blight',\n",
    "            'Tomato_Early_blight',\n",
    "            'Infected_Tomato_Late_blight',\n",
    "            'Tomato_Late_blight',\n",
    "            'Corn_healthy',\n",
    "            'Infected_Corn_Common_rust',\n",
    "            'Corn_Common_rust',\n",
    "            'Infected_Corn_Gray_leaf',\n",
    "            'Corn_Gray_leaf',\n",
    "            'Infected_Corn_Northern_Blight',\n",
    "            'Corn_Northern_Blight'\n",
    "    \n",
    "]\n",
    "\n",
    "# Draw the ground truth boxes in green (omit the label for more clarity)\n",
    "for box in batch_labels[i]:\n",
    "    xmin = box[1]\n",
    "    ymin = box[2]\n",
    "    xmax = box[3]\n",
    "    ymax = box[4]\n",
    "    #label = '{}'.format(classes[int(box[0])])\n",
    "    #current_axis.add_patch(plt.Rectangle((xmin, yminprint(\"done\")), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))  \n",
    "    #current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':'green', 'alpha':1.0})\n",
    "\n",
    "# Draw the predicted boxes in blue\n",
    "for box in y_pred_decoded[i]:\n",
    "    xmin = box[-4]\n",
    "    ymin = box[-3]\n",
    "    xmax = box[-2]\n",
    "    ymax = box[-1]\n",
    "    color = colors[int(box[0])]\n",
    "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  \n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
