{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Evaluation for Corn Leaf Detect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd7 import build_model\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from eval_utils.average_precision_evaluator import Evaluator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Set a few configuration parameters.\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "#n_classes = 31\n",
    "model_mode = 'inference'\n",
    "img_height = 256 # Height of the input images\n",
    "img_width = 256 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "n_classes = 7 # Number of positive classes\n",
    "scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
    "clip_boxes = True # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
    "normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained SSD\n",
    "\n",
    "Either load a trained model or build a model and load trained weights into it. Since the HDF5 files I'm providing contain only the weights for the various SSD versions, not the complete models, you'll have to go with the latter option when using this implementation for the first time. You can then of course save the model and next time load the full model directly, without having to build it.\n",
    "\n",
    "You can find the download links to all the trained model weights in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Build the model and load trained weights into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /hdd/new/biocaffe/notebook/ssd/keras_layers/keras_layer_DecodeDetections.py:174: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sanjeev/anaconda2/envs/tf_training/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /hdd/new/biocaffe/notebook/ssd/keras_loss_function/keras_ssd_loss.py:95: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /hdd/new/biocaffe/notebook/ssd/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 256, 256, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 256, 256, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 32) 2432        input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 256, 256, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu1 (ELU)                      (None, 256, 256, 32) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 128, 128, 32) 0           elu1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 128, 128, 48) 13872       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 128, 128, 48) 192         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu2 (ELU)                      (None, 128, 128, 48) 0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 64, 64, 48)   0           elu2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 64, 64, 64)   27712       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 64, 64, 64)   256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu3 (ELU)                      (None, 64, 64, 64)   0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 32, 32, 64)   0           elu3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 32, 32, 64)   36928       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 32, 32, 64)   256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu4 (ELU)                      (None, 32, 32, 64)   0           bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 16, 16, 64)   0           elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 16, 16, 48)   27696       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 16, 16, 48)   192         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu5 (ELU)                      (None, 16, 16, 48)   0           bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 8, 8, 48)     0           elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 8, 8, 48)     20784       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 8, 8, 48)     192         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu6 (ELU)                      (None, 8, 8, 48)     0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling2D)            (None, 4, 4, 48)     0           elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 4, 4, 32)     13856       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn7 (BatchNormalization)        (None, 4, 4, 32)     128         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu7 (ELU)                      (None, 4, 4, 32)     0           bn7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "classes4 (Conv2D)               (None, 32, 32, 32)   18464       elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes5 (Conv2D)               (None, 16, 16, 32)   13856       elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes6 (Conv2D)               (None, 8, 8, 32)     13856       elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes7 (Conv2D)               (None, 4, 4, 32)     9248        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes4 (Conv2D)                 (None, 32, 32, 16)   9232        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes5 (Conv2D)                 (None, 16, 16, 16)   6928        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes6 (Conv2D)                 (None, 8, 8, 16)     6928        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes7 (Conv2D)                 (None, 4, 4, 16)     4624        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "classes4_reshape (Reshape)      (None, 4096, 8)      0           classes4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes5_reshape (Reshape)      (None, 1024, 8)      0           classes5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes6_reshape (Reshape)      (None, 256, 8)       0           classes6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes7_reshape (Reshape)      (None, 64, 8)        0           classes7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors4 (AnchorBoxes)          (None, 32, 32, 4, 8) 0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors5 (AnchorBoxes)          (None, 16, 16, 4, 8) 0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors6 (AnchorBoxes)          (None, 8, 8, 4, 8)   0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors7 (AnchorBoxes)          (None, 4, 4, 4, 8)   0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classes_concat (Concatenate)    (None, 5440, 8)      0           classes4_reshape[0][0]           \n",
      "                                                                 classes5_reshape[0][0]           \n",
      "                                                                 classes6_reshape[0][0]           \n",
      "                                                                 classes7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "boxes4_reshape (Reshape)        (None, 4096, 4)      0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes5_reshape (Reshape)        (None, 1024, 4)      0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes6_reshape (Reshape)        (None, 256, 4)       0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes7_reshape (Reshape)        (None, 64, 4)        0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4_reshape (Reshape)      (None, 4096, 8)      0           anchors4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors5_reshape (Reshape)      (None, 1024, 8)      0           anchors5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors6_reshape (Reshape)      (None, 256, 8)       0           anchors6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors7_reshape (Reshape)      (None, 64, 8)        0           anchors7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes_softmax (Activation)    (None, 5440, 8)      0           classes_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes_concat (Concatenate)      (None, 5440, 4)      0           boxes4_reshape[0][0]             \n",
      "                                                                 boxes5_reshape[0][0]             \n",
      "                                                                 boxes6_reshape[0][0]             \n",
      "                                                                 boxes7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "anchors_concat (Concatenate)    (None, 5440, 8)      0           anchors4_reshape[0][0]           \n",
      "                                                                 anchors5_reshape[0][0]           \n",
      "                                                                 anchors6_reshape[0][0]           \n",
      "                                                                 anchors7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 5440, 20)     0           classes_softmax[0][0]            \n",
      "                                                                 boxes_concat[0][0]               \n",
      "                                                                 anchors_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoded_predictions (DecodeDete (None, <tf.Tensor 't 0           predictions[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 227,760\n",
      "Trainable params: 227,088\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = build_model(image_size=(img_height, img_width, img_channels),\n",
    "                    n_classes=n_classes,\n",
    "                    mode='inference',\n",
    "                    l2_regularization=0.0005,\n",
    "                    scales=scales,\n",
    "                    aspect_ratios_global=aspect_ratios,\n",
    "                    aspect_ratios_per_layer=None,\n",
    "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                    steps=steps,\n",
    "                    offsets=offsets,\n",
    "                    clip_boxes=clip_boxes,\n",
    "                    variances=variances,\n",
    "                    normalize_coords=normalize_coords,\n",
    "                    subtract_mean=intensity_mean,\n",
    "                    divide_by_stddev=intensity_range)\n",
    "\n",
    "# 2: Optional: Load some weights\n",
    "\n",
    "#model.load_weights('./ssd7_weights.h5', by_name=True)\n",
    "\n",
    "#weights_path = 'VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
    "\n",
    "weights_path = 'ssd7_corn_leaf_epoch-13.h5'\n",
    "\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an Adam optimizer and the SSD loss function and compile the model\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load a trained model\n",
    "\n",
    "We set `model_mode` to 'inference' above, so the evaluator expects that you load a model that was built in 'inference' mode. If you're loading a model that was built in 'training' mode, change the `model_mode` parameter accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "#model_path = 'ssd7_leaf10_epoch-117.h5'\n",
    "\n",
    "model_path = 'ssd7_leaf31_epoch-07.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a data generator for the evaluation dataset\n",
    "\n",
    "Instantiate a `DataGenerator` that will serve the evaluation dataset during the prediction phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing image set 'test_corn.txt':   0%|          | 0/57 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing image set 'test_corn.txt':  26%|██▋       | 15/57 [00:00<00:00, 149.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing image set 'test_corn.txt':  54%|█████▍    | 31/57 [00:00<00:00, 151.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Processing image set 'test_corn.txt': 100%|██████████| 57/57 [00:00<00:00, 189.97it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "dataset = DataGenerator()\n",
    "\n",
    "\n",
    "VOC_2019_images_dir      = '/hdd/data/LeafDetectData/LEAF2019/JPEGImages/'\n",
    "\n",
    "VOC_2019_annotations_dir      = '/hdd/data/LeafDetectData/LEAF2019/Annotations/'\n",
    "\n",
    "VOC_2019_trainval_image_set_filename = '/hdd/data/LeafDetectData/LEAF2019/ImageSets/Main/trainval_corn.txt'\n",
    "\n",
    "VOC_2019_test_image_set_filename     = '/hdd/data/LeafDetectData/LEAF2019/ImageSets/Main/test_corn.txt'\n",
    "\n",
    "classes = [ 'background',\n",
    "            'Corn_healthy',\n",
    "            'Infected_Corn_Common_rust',\n",
    "            'Corn_Common_rust',\n",
    "            'Infected_Corn_Gray_leaf',\n",
    "            'Corn_Gray_leaf',\n",
    "            'Infected_Corn_Northern_Blight',\n",
    "            'Corn_Northern_Blight'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "dataset.parse_xml(images_dirs=[VOC_2019_images_dir],\n",
    "                  image_set_filenames=[VOC_2019_test_image_set_filename],\n",
    "                  annotations_dirs=[VOC_2019_annotations_dir],\n",
    "                  classes=classes,\n",
    "                  include_classes='all',\n",
    "                  exclude_truncated=False,\n",
    "                  exclude_difficult=False,\n",
    "                  ret=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the evaluation\n",
    "\n",
    "Now that we have instantiated a model and a data generator to serve the dataset, we can set up the evaluator and run the evaluation.\n",
    "\n",
    "The evaluator is quite flexible: It can compute the average precisions according to the Pascal VOC pre-2010 algorithm, which samples 11 equidistant points of the precision-recall curves, or according to the Pascal VOC post-2010 algorithm, which integrates numerically over the entire precision-recall curves instead of sampling a few individual points. You could also change the number of sampled recall points or the required IoU overlap for a prediction to be considered a true positive, among other things. Check out the `Evaluator`'s documentation for details on all the arguments.\n",
    "\n",
    "In its default settings, the evaluator's algorithm is identical to the official Pascal VOC pre-2010 Matlab detection evaluation algorithm, so you don't really need to tweak anything unless you want to.\n",
    "\n",
    "The evaluator roughly performs the following steps: It runs predictions over the entire given dataset, then it matches these predictions to the ground truth boxes, then it computes the precision-recall curves for each class, then it samples 11 equidistant points from these precision-recall curves to compute the average precision for each class, and finally it computes the mean average precision over all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the evaluation dataset: 57\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Producing predictions batch-wise:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Producing predictions batch-wise:  25%|██▌       | 1/4 [00:01<00:03,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "Producing predictions batch-wise:  50%|█████     | 2/4 [00:02<00:02,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "Producing predictions batch-wise:  75%|███████▌  | 3/4 [00:03<00:01,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "Producing predictions batch-wise: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 1/7.:   0%|          | 0/37 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 1/7.: 100%|██████████| 37/37 [00:00<00:00, 2013.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 2/7.:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 2/7.: 100%|██████████| 50/50 [00:00<00:00, 2259.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/4562 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:   0%|          | 0/4562 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:  10%|█         | 469/4562 [00:00<00:00, 4684.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:  23%|██▎       | 1052/4562 [00:00<00:00, 4977.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:  38%|███▊      | 1725/4562 [00:00<00:00, 5397.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:  52%|█████▏    | 2352/4562 [00:00<00:00, 5632.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.:  71%|███████   | 3235/4562 [00:00<00:00, 6318.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 3/7.: 100%|██████████| 4562/4562 [00:00<00:00, 8127.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 4/7.:   0%|          | 0/72 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 4/7.: 100%|██████████| 72/72 [00:00<00:00, 2203.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/2829 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.:   0%|          | 0/2829 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.:  20%|█▉        | 562/2829 [00:00<00:00, 5615.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.:  43%|████▎     | 1226/2829 [00:00<00:00, 5886.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.:  66%|██████▋   | 1877/2829 [00:00<00:00, 6060.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.:  93%|█████████▎| 2623/2829 [00:00<00:00, 6420.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 5/7.: 100%|██████████| 2829/2829 [00:00<00:00, 6514.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 6/7.:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 6/7.: 100%|██████████| 26/26 [00:00<00:00, 4983.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/3824 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 7/7.:   0%|          | 0/3824 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 7/7.:  71%|███████▏  | 2728/3824 [00:00<00:00, 27277.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Matching predictions to ground truth, class 7/7.: 100%|██████████| 3824/3824 [00:00<00:00, 26707.57it/s]\u001b[A\u001b[AComputing precisions and recalls, class 1/7\n",
      "Computing precisions and recalls, class 2/7\n",
      "Computing precisions and recalls, class 3/7\n",
      "Computing precisions and recalls, class 4/7\n",
      "Computing precisions and recalls, class 5/7\n",
      "Computing precisions and recalls, class 6/7\n",
      "Computing precisions and recalls, class 7/7\n",
      "Computing average precision, class 1/7\n",
      "Computing average precision, class 2/7\n",
      "Computing average precision, class 3/7\n",
      "Computing average precision, class 4/7\n",
      "Computing average precision, class 5/7\n",
      "Computing average precision, class 6/7\n",
      "Computing average precision, class 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/new/biocaffe/notebook/ssd/eval_utils/average_precision_evaluator.py:772: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cumulative_recall = tp / self.num_gt_per_class[class_id] # 1D array with shape `(num_predictions,)`\n",
      "/hdd/new/biocaffe/notebook/ssd/eval_utils/average_precision_evaluator.py:834: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cum_prec_recall_greater_t = cumulative_precision[cumulative_recall >= t]\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model=model,\n",
    "                      n_classes=n_classes,\n",
    "                      data_generator=dataset,\n",
    "                      model_mode=model_mode)\n",
    "\n",
    "results = evaluator(img_height=img_height,\n",
    "                    img_width=img_width,\n",
    "                    batch_size=16,\n",
    "                    data_generator_mode='resize',\n",
    "                    round_confidences=False,\n",
    "                    matching_iou_threshold=0.5,\n",
    "                    border_pixels='include',\n",
    "                    sorting_algorithm='quicksort',\n",
    "                    average_precision_mode='sample',\n",
    "                    num_recall_points=11,\n",
    "                    ignore_neutral_boxes=True,\n",
    "                    return_precisions=True,\n",
    "                    return_recalls=True,\n",
    "                    return_average_precisions=True,\n",
    "                    verbose=True)\n",
    "\n",
    "mean_average_precision, average_precisions, precisions, recalls = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Visualize the results\n",
    "\n",
    "Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corn_healthy    AP  1.0\n",
      "Infected_Corn_Common_rust  AP  1.0\n",
      "Corn_Common_rust  AP  0.212\n",
      "Infected_Corn_Gray_leaf  AP  0.832\n",
      "Corn_Gray_leaf  AP  0.329\n",
      "Infected_Corn_Northern_Blight  AP  0.0\n",
      "Corn_Northern_Blight  AP  0.0\n",
      "\n",
      "              mAP   0.482\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(average_precisions)):\n",
    "    print(\"{:<14}{:<6}{}\".format(classes[i], '  AP', round(average_precisions[i], 3)))\n",
    "print()\n",
    "print(\"{:<14}{:<6}{}\".format('','mAP', round(mean_average_precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = max((n_classes + 1) // 2, 2)\n",
    "n = 2\n",
    "\n",
    "fig, cells = plt.subplots(m, n, figsize=(n*8,m*8))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if n*i+j+1 > n_classes: break\n",
    "        cells[i, j].plot(recalls[n*i+j+1], precisions[n*i+j+1], color='blue', linewidth=1.0)\n",
    "        cells[i, j].set_xlabel('recall', fontsize=14)\n",
    "        cells[i, j].set_ylabel('precision', fontsize=14)\n",
    "        cells[i, j].grid(True)\n",
    "        cells[i, j].set_xticks(np.linspace(0,1,11))\n",
    "        cells[i, j].set_yticks(np.linspace(0,1,11))\n",
    "        cells[i, j].set_title(\"{}, AP: {:.3f}\".format(classes[n*i+j+1], average_precisions[n*i+j+1]), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced use\n",
    "\n",
    "`Evaluator` objects maintain copies of all relevant intermediate results like predictions, precisions and recalls, etc., so in case you want to experiment with different parameters, e.g. different IoU overlaps, there is no need to compute the predictions all over again every time you make a change to a parameter. Instead, you can only update the computation from the point that is affected onwards.\n",
    "\n",
    "The evaluator's `__call__()` method is just a convenience wrapper that executes its other methods in the correct order. You could just call any of these other methods individually as shown below (but you have to make sure to call them in the correct order).\n",
    "\n",
    "Note that the example below uses the same evaluator object as above. Say you wanted to compute the Pascal VOC post-2010 'integrate' version of the average precisions instead of the pre-2010 version computed above. The evaluator object still has an internal copy of all the predictions, and since computing the predictions makes up the vast majority of the overall computation time and since the predictions aren't affected by changing the average precision computation mode, we skip computing the predictions again and instead only compute the steps that come after the prediction phase of the evaluation. We could even skip the matching part, since it isn't affected by changing the average precision mode either. In fact, we would only have to call `compute_average_precisions()` `compute_mean_average_precision()` again, but for the sake of illustration we'll re-do the other computations, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.get_num_gt_per_class(ignore_neutral_boxes=True,\n",
    "                               verbose=False,\n",
    "                               ret=False)\n",
    "\n",
    "evaluator.match_predictions(ignore_neutral_boxes=True,\n",
    "                            matching_iou_threshold=0.5,\n",
    "                            border_pixels='include',\n",
    "                            sorting_algorithm='quicksort',\n",
    "                            verbose=True,\n",
    "                            ret=False)\n",
    "\n",
    "precisions, recalls = evaluator.compute_precision_recall(verbose=True, ret=True)\n",
    "\n",
    "average_precisions = evaluator.compute_average_precisions(mode='integrate',\n",
    "                                                          num_recall_points=11,\n",
    "                                                          verbose=True,\n",
    "                                                          ret=True)\n",
    "\n",
    "mean_average_precision = evaluator.compute_mean_average_precision(ret=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(average_precisions)):\n",
    "    print(\"{:<14}{:<6}{}\".format(classes[i], '   AP', round(average_precisions[i], 3)))\n",
    "print()\n",
    "print(\"{:<14}{:<6}{}\".format('','mAP', round(mean_average_precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
